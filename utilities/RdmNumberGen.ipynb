{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ULWc64MKE1v6",
        "YIMCIyNQE6xh",
        "1ljva_OeFpg-",
        "QJkQm4eBFtFd",
        "Rskn0BPrFcPE",
        "5cxQMzvsFhgg",
        "ju2yomSNSf_V",
        "wqqh6ecVSjSa",
        "vtM5YCpjS5sn"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# for coinflip\n",
        "#!pip install -U click==8.0.1\n",
        "#!pip install -U Jinja2==3.0\n",
        "#!pip install typing-extensions\n",
        "# coinflip 0.1.5 requires click<8.0.0,>=7.1.2, but you have click 8.0.1 which is incompatible.\n",
        "# coinflip 0.1.5 requires Jinja2<3.0.0,>=2.11.2, but you have jinja2 3.0.0 which is incompatible.\n",
        "# it doesn't work \n",
        "# incompatible issue"
      ],
      "metadata": {
        "id": "26XxhugQKjlQ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install coinflip"
      ],
      "metadata": {
        "id": "DxGCgiCUORcy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install markupsafe==2.0.1"
      ],
      "metadata": {
        "id": "sC8H5I_3Ohcs"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import decimal\n",
        "import itertools\n",
        "import numpy\n",
        "from math import isqrt\n",
        "import scipy.special as spc\n",
        "import scipy.fftpack as sff\n",
        "import scipy.stats as sst"
      ],
      "metadata": {
        "id": "XDosIpVg0w6d"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from coinflip.randtests import monobit\n",
        "# monobit from https://gist.github.com/StuartGordonReid/3b7926ab5c9a3319bfc2"
      ],
      "metadata": {
        "id": "iqPNSc-ZN8xU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "DCbwu__Lu6eC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (can ignore) old methods: use pi and prime sqrt but with limited length"
      ],
      "metadata": {
        "id": "ULWc64MKE1v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prime(n):\n",
        "  # check if prime number \n",
        "  #from https://www.quora.com/How-can-we-find-the-closest-prime-number-to-a-given-numer-n-in-Python\n",
        "\tisprime = True \n",
        "\tif n<2: \n",
        "\t\tisprime = False \n",
        "\telse: \n",
        "\t\tfor i in range(2,n): \n",
        "\t\t\tif n%i==0: \n",
        "\t\t\t\tisprime = False \n",
        "\t\t\t\tbreak \n",
        "\treturn isprime \n",
        "\n",
        "def generate_prime(n):\n",
        "  flag = True\n",
        "  i = 1\n",
        "  if prime(n): \n",
        "    return n\n",
        "  else: \n",
        "    while flag: \n",
        "      if prime(n+i) and prime(n-i): \n",
        "        # both n - 1 and n+1 are prime\n",
        "        return random.choice(n-i,n+i)\n",
        "      elif prime(n-i): \n",
        "        return n-1\n",
        "      elif prime(n+i): \n",
        "        return n+1\n",
        "      i += 1"
      ],
      "metadata": {
        "id": "c10N4eim7_zi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_old(input,population_size):\n",
        "  # For getting a irrational number, we have 2 methods\n",
        "\n",
        "  ## Method 1: pi / user input\n",
        "  # irrational_number = math.pi/input # only 16 digits\n",
        "\n",
        "  ## Method 2: prime number square root, if not prime input, convert to the closest prime number\n",
        "  irrational_number = math.sqrt(generate_prime(input))\n",
        "\n",
        "  # only use the part after decimal to generate random number\n",
        "  before, after = str(irrational_number).split('.')\n",
        "  decimal_part = (int(after)*10 if len(after)==1 else int(after))\n",
        "  population = [None] * population_size\n",
        "  # convert number to a list of digits\n",
        "  decimal_list = list(map(int, str(decimal_part)))\n",
        "  # use each digit to generate binary sequence\n",
        "  for i in range(population_size):\n",
        "    converted_binary = decimal_to_binary(decimal_list[i])\n",
        "    # e.g. split binary 1000 to [1,0,0,0] for mutation\n",
        "    population[i] = list(str(converted_binary))\n",
        "  return population"
      ],
      "metadata": {
        "id": "AujsZIVau9wH"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### new method: use decimal.decimal to avoid length limitation, to get the sqrt of prime number"
      ],
      "metadata": {
        "id": "YIMCIyNQE6xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decimal_to_binary(decimal_num):\n",
        "  bi = bin(decimal_num).replace(\"0b\", \"\")\n",
        "  if len(bi) < 4:\n",
        "    bi = \"0\" * (4 - len(bi)) + bi\n",
        "  return bi"
      ],
      "metadata": {
        "id": "7I8qgJBnIp1e"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sqrt_digits(n, d):\n",
        "    decimal.getcontext().prec = d + 1 # set precision to d+1 decimal places\n",
        "    x = decimal.Decimal(n)\n",
        "    y = decimal.Decimal(0)\n",
        "    for i in range(d):\n",
        "        y = (x + decimal.Decimal(n)/x) / decimal.Decimal(2)\n",
        "        if y == x: # check if the square root has converged\n",
        "            break\n",
        "        x = y\n",
        "    digits = str(y).replace('.', '')\n",
        "    return digits[:d]"
      ],
      "metadata": {
        "id": "Mmo7O6QSCqC8"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize(input,population_size):\n",
        "  irrational_number = sqrt_digits(input,population_size)\n",
        "  population = [None] * population_size\n",
        "  # convert number to a list of digits\n",
        "  decimal_list = list(map(int, str(irrational_number)))\n",
        "  # use each digit to generate binary sequence\n",
        "  for i in range(population_size):\n",
        "    converted_binary = decimal_to_binary(decimal_list[i])\n",
        "    # e.g. split binary 1000 to [1,0,0,0] for mutation\n",
        "    population[i] = list(str(converted_binary))\n",
        "  return population"
      ],
      "metadata": {
        "id": "LjX1qEQ7D2T_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test initialization \n",
        "pop = initialize(input = 77, population_size = 100)\n",
        "print(pop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tohL-VUuCuRZ",
        "outputId": "ecce10a2-3aef-4a37-b745-1de4b74488ec"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['1', '0', '0', '0'], ['0', '1', '1', '1'], ['0', '1', '1', '1'], ['0', '1', '0', '0'], ['1', '0', '0', '1'], ['0', '1', '1', '0'], ['0', '1', '0', '0'], ['0', '0', '1', '1'], ['1', '0', '0', '0'], ['0', '1', '1', '1'], ['0', '0', '1', '1'], ['1', '0', '0', '1'], ['0', '0', '1', '0'], ['0', '0', '0', '1'], ['0', '0', '1', '0'], ['0', '0', '1', '0'], ['0', '0', '0', '0'], ['0', '1', '1', '0'], ['0', '0', '0', '0'], ['0', '1', '0', '0'], ['0', '0', '0', '0'], ['0', '1', '1', '0'], ['0', '0', '1', '1'], ['1', '0', '0', '0'], ['1', '0', '0', '0'], ['0', '0', '1', '1'], ['0', '0', '0', '0'], ['0', '1', '1', '1'], ['0', '1', '0', '0'], ['0', '0', '0', '1'], ['0', '1', '1', '0'], ['0', '0', '1', '1'], ['0', '0', '0', '0'], ['1', '0', '0', '1'], ['0', '1', '0', '1'], ['0', '1', '1', '0'], ['0', '0', '0', '0'], ['1', '0', '0', '0'], ['0', '1', '1', '1'], ['0', '1', '0', '1'], ['1', '0', '0', '0'], ['0', '1', '1', '1'], ['0', '1', '1', '0'], ['1', '0', '0', '0'], ['0', '0', '1', '0'], ['0', '1', '1', '1'], ['0', '1', '0', '1'], ['0', '1', '0', '1'], ['0', '1', '0', '0'], ['0', '1', '0', '1'], ['0', '0', '0', '0'], ['0', '0', '1', '1'], ['0', '1', '0', '1'], ['1', '0', '0', '1'], ['0', '0', '0', '0'], ['1', '0', '0', '1'], ['0', '0', '1', '0'], ['0', '1', '1', '1'], ['0', '1', '1', '0'], ['1', '0', '0', '1'], ['0', '1', '0', '1'], ['0', '1', '1', '0'], ['0', '0', '1', '0'], ['1', '0', '0', '1'], ['0', '1', '1', '1'], ['1', '0', '0', '0'], ['0', '0', '1', '0'], ['0', '1', '1', '1'], ['0', '1', '1', '0'], ['0', '1', '0', '0'], ['0', '1', '1', '0'], ['0', '1', '0', '0'], ['0', '1', '1', '0'], ['0', '0', '1', '0'], ['0', '0', '0', '1'], ['1', '0', '0', '1'], ['0', '0', '1', '1'], ['0', '0', '0', '0'], ['0', '1', '1', '0'], ['0', '0', '1', '0'], ['1', '0', '0', '0'], ['0', '0', '0', '1'], ['0', '1', '1', '0'], ['0', '1', '1', '1'], ['0', '1', '0', '1'], ['0', '1', '1', '0'], ['1', '0', '0', '1'], ['0', '0', '1', '1'], ['0', '0', '0', '1'], ['0', '1', '0', '1'], ['0', '1', '1', '1'], ['0', '0', '0', '0'], ['0', '1', '1', '0'], ['1', '0', '0', '0'], ['0', '1', '1', '1'], ['0', '0', '0', '0'], ['0', '1', '0', '1'], ['0', '1', '1', '1'], ['0', '1', '0', '1'], ['0', '1', '1', '0']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate fitness"
      ],
      "metadata": {
        "id": "gA5fBGvAvcVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/StuartGordonReid/r4nd0m/blob/master/SourceCode/RandomnessTests.py\n",
        "\n",
        "#### problem right now:\n",
        "spectral has numpy issue, runs_test + longest_runs_test need multiple runs\n",
        "\n",
        "\n",
        "1. The Frequency (Monobit) Test, -done\n",
        "2. Frequency Test within a Block, \n",
        "3. The Runs Test, -done\n",
        "4. Tests for the Longest-Run-of-Ones in a Block, -done\n",
        "5. The Binary Matrix Rank Test, -done\n",
        "6. (has np problem)The Discrete Fourier Transform (Spectral) Test, - done\n",
        "7. The Non-overlapping Template Matching Test,  - done\n",
        "8. The Overlapping Template Matching Test,  - need more\n",
        "9. Maurer's \"Universal Statistical\" Test, - done\n",
        "10. The Linear Complexity Test, - done\n",
        "11. The Serial Test, - done\n",
        "12. The Approximate Entropy Test, -done\n",
        "13. The Cumulative Sums (Cusums) Test, -done\n",
        "14. The Random Excursions Test, and \n",
        "15. The Random Excursions Variant Test."
      ],
      "metadata": {
        "id": "k84LV6wsUT2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. monobit"
      ],
      "metadata": {
        "id": "BuH3UIPpik8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def monobit(bin_data):\n",
        "    \"\"\"\n",
        "    Note that this description is taken from the NIST documentation [1]\n",
        "    [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  \n",
        "    The focus of this test is the proportion of zeros and ones for the entire sequence. The purpose of this test is\n",
        "    to determine whether the number of ones and zeros in a sequence are approximately the same as would be expected\n",
        "    for a truly random sequence. This test assesses the closeness of the fraction of ones to 1/2, that is the number\n",
        "    of ones and zeros ina  sequence should be about the same. All subsequent tests depend on this test.\n",
        "  \n",
        "    :param bin_data: a binary string\n",
        "    :return: the p-value from the test\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    # If the char is 0 minus 1, else add 1\n",
        "    for char in bin_data:\n",
        "        if char == '0':\n",
        "            count -= 1\n",
        "        else:\n",
        "            count += 1\n",
        "    # Calculate the p value\n",
        "    sobs = count / math.sqrt(len(bin_data))\n",
        "    p_val = spc.erfc(math.fabs(sobs) / math.sqrt(2))\n",
        "    return p_val"
      ],
      "metadata": {
        "id": "cyuAdaBCUMp0"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. block_frequency"
      ],
      "metadata": {
        "id": "U9yqqOufioJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def block_frequency(bin_data, block_size=128):\n",
        "    \"\"\"\n",
        "    Note that this description is taken from the NIST documentation [1]\n",
        "    [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "    The focus of this tests is the proportion of ones within M-bit blocks. The purpose of this tests is to determine\n",
        "    whether the frequency of ones in an M-bit block is approximately M/2, as would be expected under an assumption\n",
        "    of randomness. For block size M=1, this test degenerates to the monobit frequency test.\n",
        "    :param bin_data: a binary string\n",
        "    :return: the p-value from the test\n",
        "    :param block_size: the size of the blocks that the binary sequence is partitioned into\n",
        "    \"\"\"\n",
        "    # Work out the number of blocks, discard the remainder\n",
        "    num_blocks = math.floor(len(bin_data) / block_size)\n",
        "    block_start, block_end = 0, block_size\n",
        "    # Keep track of the proportion of ones per block\n",
        "    proportion_sum = 0.0\n",
        "    for i in range(num_blocks):\n",
        "        # Slice the binary string into a block\n",
        "        block_data = bin_data[block_start:block_end]\n",
        "        # Keep track of the number of ones\n",
        "        ones_count = 0\n",
        "        for char in block_data:\n",
        "            if char == '1':\n",
        "                ones_count += 1\n",
        "        pi = ones_count / block_size\n",
        "        proportion_sum += pow(pi - 0.5, 2.0)\n",
        "        # Update the slice locations\n",
        "        block_start += block_size\n",
        "        block_end += block_size\n",
        "    # Calculate the p-value\n",
        "    chi_squared = 4.0 * block_size * proportion_sum\n",
        "    p_val = spc.gammaincc(num_blocks / 2, chi_squared / 2)\n",
        "    return p_val"
      ],
      "metadata": {
        "id": "zIJJmLVnYN4x"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### independent_runs"
      ],
      "metadata": {
        "id": "Yjz2R7p2iqX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def independent_runs(bin_data: str):\n",
        "        \"\"\"\n",
        "        Note that this description is taken from the NIST documentation [1]\n",
        "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "        The focus of this tests if the total number of runs in the sequences, where a run is an uninterrupted sequence\n",
        "        of identical bits. A run of length k consists of k identical bits and is bounded before and after with a bit of\n",
        "        the opposite value. The purpose of the runs tests is to determine whether the number of runs of ones and zeros\n",
        "        of various lengths is as expected for a random sequence. In particular, this tests determines whether the\n",
        "        oscillation between zeros and ones is either too fast or too slow.\n",
        "        :param bin_data: a binary string\n",
        "        :return: the p-value from the test\n",
        "        \"\"\"\n",
        "        ones_count, n = 0, len(bin_data)\n",
        "        for char in bin_data:\n",
        "            if char == '1':\n",
        "                ones_count += 1\n",
        "        p, vobs = float(ones_count / n), 1\n",
        "        tau = 2 / math.sqrt(len(bin_data))\n",
        "        if abs(p - 0.5) > tau:\n",
        "            return 0.0\n",
        "        else:\n",
        "            for i in range(1, n):\n",
        "                if bin_data[i] != bin_data[i - 1]:\n",
        "                    vobs += 1\n",
        "            # expected_runs = 1 + 2 * (n - 1) * 0.5 * 0.5\n",
        "            # print(\"\\t\", Colours.Italics + \"Observed runs =\", vobs, \"Expected runs\", expected_runs, Colours.End)\n",
        "            num = abs(vobs - 2.0 * n * p * (1.0 - p))\n",
        "            den = 2.0 * math.sqrt(2.0 * n) * p * (1.0 - p)\n",
        "            p_val = spc.erfc(float(num / den))\n",
        "            return p_val\n"
      ],
      "metadata": {
        "id": "NYLHWB6Sdan7"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### longest_runs"
      ],
      "metadata": {
        "id": "kP3YVo2qitB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def longest_runs(bin_data: str):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of the tests is the longest run of ones within M-bit blocks. The purpose of this tests is to determine\n",
        "  whether the length of the longest run of ones within the tested sequences is consistent with the length of the\n",
        "  longest run of ones that would be expected in a random sequence. Note that an irregularity in the expected\n",
        "  length of the longest run of ones implies that there is also an irregularity ub tge expected length of the long\n",
        "  est run of zeroes. Therefore, only one test is necessary for this statistical tests of randomness\n",
        "  :param bin_data: a binary string\n",
        "  :return: the p-value from the test\n",
        "  \"\"\"\n",
        "  if len(bin_data) < 128:\n",
        "      print(\"\\t\", \"Not enough data to run test!\")\n",
        "      return -1.0\n",
        "  elif len(bin_data) < 6272:\n",
        "      k, m = 3, 8\n",
        "      v_values = [1, 2, 3, 4]\n",
        "      pik_values = [0.21484375, 0.3671875, 0.23046875, 0.1875]\n",
        "  elif len(bin_data) < 75000:\n",
        "      k, m = 5, 128\n",
        "      v_values = [4, 5, 6, 7, 8, 9]\n",
        "      pik_values = [0.1174035788, 0.242955959, 0.249363483, 0.17517706, 0.102701071, 0.112398847]\n",
        "  else:\n",
        "      k, m = 6, 10000\n",
        "      v_values = [10, 11, 12, 13, 14, 15, 16]\n",
        "      pik_values = [0.0882, 0.2092, 0.2483, 0.1933, 0.1208, 0.0675, 0.0727]\n",
        "\n",
        "  # Work out the number of blocks, discard the remainder\n",
        "  # pik = [0.2148, 0.3672, 0.2305, 0.1875]\n",
        "  num_blocks = math.floor(len(bin_data) / m)\n",
        "  frequencies = numpy.zeros(k + 1)\n",
        "  block_start, block_end = 0, m\n",
        "  for i in range(num_blocks):\n",
        "      # Slice the binary string into a block\n",
        "      block_data = bin_data[block_start:block_end]\n",
        "      # Keep track of the number of ones\n",
        "      max_run_count, run_count = 0, 0\n",
        "      for j in range(0, m):\n",
        "          if block_data[j] == '1':\n",
        "              run_count += 1\n",
        "              max_run_count = max(max_run_count, run_count)\n",
        "          else:\n",
        "              max_run_count = max(max_run_count, run_count)\n",
        "              run_count = 0\n",
        "      max_run_count = max(max_run_count, run_count)\n",
        "      if max_run_count < v_values[0]:\n",
        "          frequencies[0] += 1\n",
        "      for j in range(k):\n",
        "          if max_run_count == v_values[j]:\n",
        "              frequencies[j] += 1\n",
        "      if max_run_count > v_values[k - 1]:\n",
        "          frequencies[k] += 1\n",
        "      block_start += m\n",
        "      block_end += m\n",
        "  # print(frequencies)\n",
        "  chi_squared = 0\n",
        "  for i in range(len(frequencies)):\n",
        "      chi_squared += (pow(frequencies[i] - (num_blocks * pik_values[i]), 2.0)) / (num_blocks * pik_values[i])\n",
        "  p_val = spc.gammaincc(float(k / 2), float(chi_squared / 2))\n",
        "  return p_val\n"
      ],
      "metadata": {
        "id": "nVw9XRqXdf-X"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### matrix_rank"
      ],
      "metadata": {
        "id": "RdgGE9FiivQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_rank(bin_data: str, matrix_size=32):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of the test is the rank of disjoint sub-matrices of the entire sequence. The purpose of this test is\n",
        "  to check for linear dependence among fixed length sub strings of the original sequence. Note that this test\n",
        "  also appears in the DIEHARD battery of tests.\n",
        "  :param bin_data: a binary string\n",
        "  :return: the p-value from the test\n",
        "  \"\"\"\n",
        "  shape = (matrix_size, matrix_size)\n",
        "  n = len(bin_data)\n",
        "  block_size = int(matrix_size * matrix_size)\n",
        "  num_m = math.floor(n / (matrix_size * matrix_size))\n",
        "  block_start, block_end = 0, block_size\n",
        "  # print(q, n, num_m, block_size)\n",
        "\n",
        "  if num_m > 0:\n",
        "      max_ranks = [0, 0, 0]\n",
        "      for im in range(num_m):\n",
        "          block_data = bin_data[block_start:block_end]\n",
        "          block = numpy.zeros(len(block_data))\n",
        "          for i in range(len(block_data)):\n",
        "              if block_data[i] == '1':\n",
        "                  block[i] = 1.0\n",
        "          m = block.reshape(shape)\n",
        "          ranker = BinaryMatrix(m, matrix_size, matrix_size)\n",
        "          rank = ranker.compute_rank()\n",
        "          # print(rank)\n",
        "          if rank == matrix_size:\n",
        "              max_ranks[0] += 1\n",
        "          elif rank == (matrix_size - 1):\n",
        "              max_ranks[1] += 1\n",
        "          else:\n",
        "              max_ranks[2] += 1\n",
        "          # Update index trackers\n",
        "          block_start += block_size\n",
        "          block_end += block_size\n",
        "\n",
        "      piks = [1.0, 0.0, 0.0]\n",
        "      for x in range(1, 50):\n",
        "          piks[0] *= 1 - (1.0 / (2 ** x))\n",
        "      piks[1] = 2 * piks[0]\n",
        "      piks[2] = 1 - piks[0] - piks[1]\n",
        "\n",
        "      chi = 0.0\n",
        "      for i in range(len(piks)):\n",
        "          chi += pow((max_ranks[i] - piks[i] * num_m), 2.0) / (piks[i] * num_m)\n",
        "      p_val = math.exp(-chi / 2)\n",
        "      return p_val\n",
        "  else:\n",
        "      return -1.0\n"
      ],
      "metadata": {
        "id": "BiJwtERHdjLc"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### spectral"
      ],
      "metadata": {
        "id": "out3Vvt6ixXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spectral(bin_data: str):\n",
        "        \"\"\"\n",
        "        Note that this description is taken from the NIST documentation [1]\n",
        "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "        The focus of this test is the peak heights in the Discrete Fourier Transform of the sequence. The purpose of\n",
        "        this test is to detect periodic features (i.e., repetitive patterns that are near each other) in the tested\n",
        "        sequence that would indicate a deviation from the assumption of randomness. The intention is to detect whether\n",
        "        the number of peaks exceeding the 95 % threshold is significantly different than 5 %.\n",
        "        :param bin_data: a binary string\n",
        "        :return: the p-value from the test\n",
        "        \"\"\"\n",
        "        n = len(bin_data)\n",
        "        plus_minus_one = []\n",
        "        for char in bin_data:\n",
        "            if char == '0':\n",
        "                plus_minus_one.append(-1)\n",
        "            elif char == '1':\n",
        "                plus_minus_one.append(1)\n",
        "        # Product discrete fourier transform of plus minus one\n",
        "        s = sff.fft(plus_minus_one)\n",
        "        modulus = numpy.abs(s[0:n / 2])\n",
        "        tau = numpy.sqrt(numpy.log(1 / 0.05) * n)\n",
        "        # Theoretical number of peaks\n",
        "        count_n0 = 0.95 * (n / 2)\n",
        "        # Count the number of actual peaks m > T\n",
        "        count_n1 = len(numpy.where(modulus < tau)[0])\n",
        "        # Calculate d and return the p value statistic\n",
        "        d = (count_n1 - count_n0) / numpy.sqrt(n * 0.95 * 0.05 / 4)\n",
        "        p_val = spc.erfc(abs(d) / numpy.sqrt(2))\n",
        "        return p_val"
      ],
      "metadata": {
        "id": "sqZwfCTjdl3o"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### universal"
      ],
      "metadata": {
        "id": "b6lecpAEiy3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def universal(bin_data: str):\n",
        "    \"\"\"\n",
        "    Note that this description is taken from the NIST documentation [1]\n",
        "    [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "    The focus of this test is the number of bits between matching patterns (a measure that is related to the\n",
        "    length of a compressed sequence). The purpose of the test is to detect whether or not the sequence can be\n",
        "    significantly compressed without loss of information. A significantly compressible sequence is considered\n",
        "    to be non-random. **This test is always skipped because the requirements on the lengths of the binary\n",
        "    strings are too high i.e. there have not been enough trading days to meet the requirements.\n",
        "    :param bin_data: a binary string\n",
        "    :return: the p-value from the test\n",
        "    \"\"\"\n",
        "    # The below table is less relevant for us traders and markets than it is for security people\n",
        "    n = len(bin_data)\n",
        "    pattern_size = 5\n",
        "    if n >= 387840:\n",
        "        pattern_size = 6\n",
        "    if n >= 904960:\n",
        "        pattern_size = 7\n",
        "    if n >= 2068480:\n",
        "        pattern_size = 8\n",
        "    if n >= 4654080:\n",
        "        pattern_size = 9\n",
        "    if n >= 10342400:\n",
        "        pattern_size = 10\n",
        "    if n >= 22753280:\n",
        "        pattern_size = 11\n",
        "    if n >= 49643520:\n",
        "        pattern_size = 12\n",
        "    if n >= 107560960:\n",
        "        pattern_size = 13\n",
        "    if n >= 231669760:\n",
        "        pattern_size = 14\n",
        "    if n >= 496435200:\n",
        "        pattern_size = 15\n",
        "    if n >= 1059061760:\n",
        "        pattern_size = 16\n",
        "\n",
        "    if 5 < pattern_size < 16:\n",
        "        # Create the biggest binary string of length pattern_size\n",
        "        ones = \"\"\n",
        "        for i in range(pattern_size):\n",
        "            ones += \"1\"\n",
        "\n",
        "        # How long the state list should be\n",
        "        num_ints = int(ones, 2)\n",
        "        vobs = numpy.zeros(num_ints + 1)\n",
        "\n",
        "        # Keeps track of the blocks, and whether were are initializing or summing\n",
        "        num_blocks = math.floor(n / pattern_size)\n",
        "        init_bits = 10 * pow(2, pattern_size)\n",
        "        test_bits = num_blocks - init_bits\n",
        "\n",
        "        # These are the expected values assuming randomness (uniform)\n",
        "        c = 0.7 - 0.8 / pattern_size + (4 + 32 / pattern_size) * pow(test_bits, -3 / pattern_size) / 15\n",
        "        variance = [0, 0, 0, 0, 0, 0, 2.954, 3.125, 3.238, 3.311, 3.356, 3.384, 3.401, 3.410, 3.416, 3.419, 3.421]\n",
        "        expected = [0, 0, 0, 0, 0, 0, 5.2177052, 6.1962507, 7.1836656, 8.1764248, 9.1723243,\n",
        "                    10.170032, 11.168765, 12.168070, 13.167693, 14.167488, 15.167379]\n",
        "        sigma = c * math.sqrt(variance[pattern_size] / test_bits)\n",
        "\n",
        "        cumsum = 0.0\n",
        "        for i in range(num_blocks):\n",
        "            block_start = i * pattern_size\n",
        "            block_end = block_start + pattern_size\n",
        "            block_data = bin_data[block_start: block_end]\n",
        "            # Work out what state we are in\n",
        "            int_rep = int(block_data, 2)\n",
        "\n",
        "            # Initialize the state list\n",
        "            if i < init_bits:\n",
        "                vobs[int_rep] = i + 1\n",
        "            else:\n",
        "                initial = vobs[int_rep]\n",
        "                vobs[int_rep] = i + 1\n",
        "                cumsum += math.log(i - initial + 1, 2)\n",
        "\n",
        "        # Calculate the statistic\n",
        "        phi = float(cumsum / test_bits)\n",
        "        stat = abs(phi - expected[pattern_size]) / (float(math.sqrt(2)) * sigma)\n",
        "        p_val = spc.erfc(stat)\n",
        "        return p_val\n",
        "    else:\n",
        "        return -1.0"
      ],
      "metadata": {
        "id": "MAndk1nmeeRC"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def berlekamp_massey_algorithm(block_data: str):\n",
        "    \"\"\"\n",
        "    An implementation of the Berlekamp Massey Algorithm. Taken from Wikipedia [1]\n",
        "    [1] - https://en.wikipedia.org/wiki/Berlekamp-Massey_algorithm\n",
        "    The Berlekamp–Massey algorithm is an algorithm that will find the shortest linear feedback shift register (LFSR)\n",
        "    for a given binary output sequence. The algorithm will also find the minimal polynomial of a linearly recurrent\n",
        "    sequence in an arbitrary field. The field requirement means that the Berlekamp–Massey algorithm requires all\n",
        "    non-zero elements to have a multiplicative inverse.\n",
        "    :param block_data:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    n = len(block_data)\n",
        "    c = numpy.zeros(n)\n",
        "    b = numpy.zeros(n)\n",
        "    c[0], b[0] = 1, 1\n",
        "    l, m, i = 0, -1, 0\n",
        "    int_data = [int(el) for el in block_data]\n",
        "    while i < n:\n",
        "        v = int_data[(i - l):i]\n",
        "        v = v[::-1]\n",
        "        cc = c[1:l + 1]\n",
        "        d = (int_data[i] + numpy.dot(v, cc)) % 2\n",
        "        if d == 1:\n",
        "            temp = copy.copy(c)\n",
        "            p = numpy.zeros(n)\n",
        "            for j in range(0, l):\n",
        "                if b[j] == 1:\n",
        "                    p[j + i - m] = 1\n",
        "            c = (c + p) % 2\n",
        "            if l <= 0.5 * i:\n",
        "                l = i + 1 - l\n",
        "                m = i\n",
        "                b = temp\n",
        "        i += 1\n",
        "    return l"
      ],
      "metadata": {
        "id": "BXz-70bYe6Xh"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### linear_complexity"
      ],
      "metadata": {
        "id": "PX9vDHy6i2ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_complexity(bin_data: str, block_size=500):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of this test is the length of a linear feedback shift register (LFSR). The purpose of this test is to\n",
        "  determine whether or not the sequence is complex enough to be considered random. Random sequences are\n",
        "  characterized by longer LFSRs. An LFSR that is too short implies non-randomness.\n",
        "  :param bin_data: a binary string\n",
        "  :param block_size: the size of the blocks to divide bin_data into. Recommended block_size >= 500\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  dof = 6\n",
        "  piks = [0.01047, 0.03125, 0.125, 0.5, 0.25, 0.0625, 0.020833]\n",
        "\n",
        "  t2 = (block_size / 3.0 + 2.0 / 9) / 2 ** block_size\n",
        "  mean = 0.5 * block_size + (1.0 / 36) * (9 + (-1) ** (block_size + 1)) - t2\n",
        "\n",
        "  num_blocks = int(len(bin_data) / block_size)\n",
        "  if num_blocks > 1:\n",
        "      block_end = block_size\n",
        "      block_start = 0\n",
        "      blocks = []\n",
        "      for i in range(num_blocks):\n",
        "          blocks.append(bin_data[block_start:block_end])\n",
        "          block_start += block_size\n",
        "          block_end += block_size\n",
        "\n",
        "      complexities = []\n",
        "      for block in blocks:\n",
        "          complexities.append(berlekamp_massey_algorithm(block))\n",
        "\n",
        "      t = ([-1.0 * (((-1) ** block_size) * (chunk - mean) + 2.0 / 9) for chunk in complexities])\n",
        "      vg = numpy.histogram(t, bins=[-9999999999, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 9999999999])[0][::-1]\n",
        "      im = ([((vg[ii] - num_blocks * piks[ii]) ** 2) / (num_blocks * piks[ii]) for ii in range(7)])\n",
        "\n",
        "      chi_squared = 0.0\n",
        "      for i in range(len(piks)):\n",
        "          chi_squared += im[i]\n",
        "      p_val = spc.gammaincc(dof / 2.0, chi_squared / 2.0)\n",
        "      return p_val\n",
        "  else:\n",
        "      return -1.0"
      ],
      "metadata": {
        "id": "n_JUNBbOeusm"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####serial"
      ],
      "metadata": {
        "id": "TUr80_Ofi52d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def serial(bin_data: str, pattern_length=16, method=\"first\"):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of this test is the frequency of all possible overlapping m-bit patterns across the entire\n",
        "  sequence. The purpose of this test is to determine whether the number of occurrences of the 2m m-bit\n",
        "  overlapping patterns is approximately the same as would be expected for a random sequence. Random\n",
        "  sequences have uniformity; that is, every m-bit pattern has the same chance of appearing as every other\n",
        "  m-bit pattern. Note that for m = 1, the Serial test is equivalent to the Frequency test of Section 2.1.\n",
        "  :param bin_data: a binary string\n",
        "  :param pattern_length: the length of the pattern (m)\n",
        "  :return: the P value\n",
        "  \"\"\"\n",
        "  n = len(bin_data)\n",
        "  # Add first m-1 bits to the end\n",
        "  bin_data += bin_data[:pattern_length - 1:]\n",
        "\n",
        "  # Get max length one patterns for m, m-1, m-2\n",
        "  max_pattern = ''\n",
        "  for i in range(pattern_length + 1):\n",
        "      max_pattern += '1'\n",
        "\n",
        "  # Keep track of each pattern's frequency (how often it appears)\n",
        "  vobs_one = numpy.zeros(int(max_pattern[0:pattern_length:], 2) + 1)\n",
        "  vobs_two = numpy.zeros(int(max_pattern[0:pattern_length - 1:], 2) + 1)\n",
        "  vobs_thr = numpy.zeros(int(max_pattern[0:pattern_length - 2:], 2) + 1)\n",
        "\n",
        "  for i in range(n):\n",
        "      # Work out what pattern is observed\n",
        "      vobs_one[int(bin_data[i:i + pattern_length:], 2)] += 1\n",
        "      vobs_two[int(bin_data[i:i + pattern_length - 1:], 2)] += 1\n",
        "      vobs_thr[int(bin_data[i:i + pattern_length - 2:], 2)] += 1\n",
        "\n",
        "  vobs = [vobs_one, vobs_two, vobs_thr]\n",
        "  sums = numpy.zeros(3)\n",
        "  for i in range(3):\n",
        "      for j in range(len(vobs[i])):\n",
        "          sums[i] += pow(vobs[i][j], 2)\n",
        "      sums[i] = (sums[i] * pow(2, pattern_length - i) / n) - n\n",
        "\n",
        "  # Calculate the test statistics and p values\n",
        "  del1 = sums[0] - sums[1]\n",
        "  del2 = sums[0] - 2.0 * sums[1] + sums[2]\n",
        "  p_val_one = spc.gammaincc(pow(2, pattern_length - 1) / 2, del1 / 2.0)\n",
        "  p_val_two = spc.gammaincc(pow(2, pattern_length - 2) / 2, del2 / 2.0)\n",
        "\n",
        "  # For checking the outputs\n",
        "  if method == \"first\":\n",
        "      return p_val_one\n",
        "  elif method == \"both\":\n",
        "      return p_val_one, p_val_two\n",
        "  else:\n",
        "      # I am not sure if this is correct, but it makes sense to me.\n",
        "      return min(p_val_one, p_val_two)\n"
      ],
      "metadata": {
        "id": "klGQE4jSfHL5"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### approximate_entropy"
      ],
      "metadata": {
        "id": "L7qxGL-ai8M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def approximate_entropy(bin_data: str, pattern_length=10):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  As with the Serial test of Section 2.11, the focus of this test is the frequency of all possible overlapping\n",
        "  m-bit patterns across the entire sequence. The purpose of the test is to compare the frequency of overlapping\n",
        "  blocks of two consecutive/adjacent lengths (m and m+1) against the expected result for a random sequence.\n",
        "  :param bin_data: a binary string\n",
        "  :param pattern_length: the length of the pattern (m)\n",
        "  :return: the P value\n",
        "  \"\"\"\n",
        "  n = len(bin_data)\n",
        "  # Add first m+1 bits to the end\n",
        "  # NOTE: documentation says m-1 bits but that doesnt make sense, or work.\n",
        "  bin_data += bin_data[:pattern_length + 1:]\n",
        "\n",
        "  # Get max length one patterns for m, m-1, m-2\n",
        "  max_pattern = ''\n",
        "  for i in range(pattern_length + 2):\n",
        "      max_pattern += '1'\n",
        "\n",
        "  # Keep track of each pattern's frequency (how often it appears)\n",
        "  vobs_one = numpy.zeros(int(max_pattern[0:pattern_length:], 2) + 1)\n",
        "  vobs_two = numpy.zeros(int(max_pattern[0:pattern_length + 1:], 2) + 1)\n",
        "\n",
        "  for i in range(n):\n",
        "      # Work out what pattern is observed\n",
        "      vobs_one[int(bin_data[i:i + pattern_length:], 2)] += 1\n",
        "      vobs_two[int(bin_data[i:i + pattern_length + 1:], 2)] += 1\n",
        "\n",
        "  # Calculate the test statistics and p values\n",
        "  vobs = [vobs_one, vobs_two]\n",
        "  sums = numpy.zeros(2)\n",
        "  for i in range(2):\n",
        "      for j in range(len(vobs[i])):\n",
        "          if vobs[i][j] > 0:\n",
        "              sums[i] += vobs[i][j] * math.log(vobs[i][j] / n)\n",
        "  sums /= n\n",
        "  ape = sums[0] - sums[1]\n",
        "  chi_squared = 2.0 * n * (math.log(2) - ape)\n",
        "  p_val = spc.gammaincc(pow(2, pattern_length - 1), chi_squared / 2.0)\n",
        "  return p_val\n"
      ],
      "metadata": {
        "id": "RHq8ij9dfL-W"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cumulative_sums"
      ],
      "metadata": {
        "id": "zps4__8Ai9rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cumulative_sums(bin_data: str, method=\"forward\"):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of this test is the maximal excursion (from zero) of the random walk defined by the cumulative sum of\n",
        "  adjusted (-1, +1) digits in the sequence. The purpose of the test is to determine whether the cumulative sum of\n",
        "  the partial sequences occurring in the tested sequence is too large or too small relative to the expected\n",
        "  behavior of that cumulative sum for random sequences. This cumulative sum may be considered as a random walk.\n",
        "  For a random sequence, the excursions of the random walk should be near zero. For certain types of non-random\n",
        "  sequences, the excursions of this random walk from zero will be large.\n",
        "  :param bin_data: a binary string\n",
        "  :param method: the method used to calculate the statistic\n",
        "  :return: the P-value\n",
        "  \"\"\"\n",
        "  n = len(bin_data)\n",
        "  counts = numpy.zeros(n)\n",
        "  # Calculate the statistic using a walk forward\n",
        "  if method != \"forward\":\n",
        "      bin_data = bin_data[::-1]\n",
        "\n",
        "  ix = 0\n",
        "  for char in bin_data:\n",
        "      sub = 1\n",
        "      if char == '0':\n",
        "          sub = -1\n",
        "      if ix > 0:\n",
        "          counts[ix] = counts[ix - 1] + sub\n",
        "      else:\n",
        "          counts[ix] = sub\n",
        "      ix += 1\n",
        "\n",
        "  # This is the maximum absolute level obtained by the sequence\n",
        "  abs_max = numpy.max(numpy.abs(counts))\n",
        "\n",
        "  start = int(numpy.floor(0.25 * numpy.floor(-n / abs_max) + 1))\n",
        "  end = int(numpy.floor(0.25 * numpy.floor(n / abs_max) - 1))\n",
        "  terms_one = []\n",
        "  for k in range(start, end + 1):\n",
        "      sub = sst.norm.cdf((4 * k - 1) * abs_max / numpy.sqrt(n))\n",
        "      terms_one.append(sst.norm.cdf((4 * k + 1) * abs_max / numpy.sqrt(n)) - sub)\n",
        "\n",
        "  start = int(numpy.floor(0.25 * numpy.floor(-n / abs_max - 3)))\n",
        "  end = int(numpy.floor(0.25 * numpy.floor(n / abs_max) - 1))\n",
        "  terms_two = []\n",
        "  for k in range(start, end + 1):\n",
        "      sub = sst.norm.cdf((4 * k + 1) * abs_max / numpy.sqrt(n))\n",
        "      terms_two.append(sst.norm.cdf((4 * k + 3) * abs_max / numpy.sqrt(n)) - sub)\n",
        "\n",
        "  p_val = 1.0 - numpy.sum(numpy.array(terms_one))\n",
        "  p_val += numpy.sum(numpy.array(terms_two))\n",
        "  return p_val\n"
      ],
      "metadata": {
        "id": "WAMyb6zMfSMC"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### !! Final Fitness evaluation function"
      ],
      "metadata": {
        "id": "0syAKft-i_tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness(sequence):\n",
        "  # 1. monobit test\n",
        "  monobit_test = int(monobit(sequence) > 0.01)\n",
        "\n",
        "  # 2. block frequency test\n",
        "  block_freq_test = int(block_frequency(sequence) > 0.01)\n",
        "\n",
        "  # 3. independent_runs test\n",
        "  runs_test = int(independent_runs(sequence) > 0.01)\n",
        "\n",
        "  \n",
        "  # 4. longest run\n",
        "  longest_runs_test = int(longest_runs(sequence) > 0.01)\n",
        "\n",
        "  # 5. matrix_rank\n",
        "  matrix_rank_test = int(matrix_rank(sequence) > 0.01)\n",
        "\n",
        "  # 6. spectral\n",
        "  # spectral_test = int(spectral(sequence) > 0.01)\n",
        "\n",
        "  # 7. universal\n",
        "  universal_test = int(universal(sequence) > 0.01)\n",
        "\n",
        "  # 8. linear_complexity\n",
        "  linear_complexity_test = int(linear_complexity(sequence) > 0.01)\n",
        "\n",
        "  # 9. serial\n",
        "  serial_test = int(serial(sequence) > 0.01)\n",
        "\n",
        "  # 10. approximate_entropy\n",
        "  approximate_entropy_test = int(approximate_entropy(sequence) > 0.01)\n",
        "\n",
        "  # 11. cumulative_sums\n",
        "  cumulative_sums_test = int(cumulative_sums(sequence) > 0.01)\n",
        "\n",
        "  result = monobit_test + block_freq_test + matrix_rank_test\n",
        "  ## spectral has numpy issue, runs_test + longest_runs_test need multiple runs\n",
        "  # result += spectral_test + runs_test + longest_runs_test\n",
        "  result += universal_test + linear_complexity_test + serial_test\n",
        "  result += approximate_entropy_test + cumulative_sums_test\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "m9ds3PLW0hoH"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parent Selection"
      ],
      "metadata": {
        "id": "BQ_D-hIg_Y-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tournament selection"
      ],
      "metadata": {
        "id": "1ljva_OeFpg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tournament(fitness, mating_pool_size, tournament_size):\n",
        "    \"\"\"Tournament selection without replacement\"\"\"\n",
        "    selected_to_mate = []\n",
        "    # student code starts\n",
        "    current_member = 1\n",
        "    while (current_member < mating_pool_size) or (current_member == mating_pool_size):\n",
        "        # pick k (tournament_size) individual randomly, without replacement\n",
        "        individual_indexes = range(1,len(fitness)+1) \n",
        "        picked_index = random.sample(individual_indexes, tournament_size) #  sample does not allow duplicate elements in a sequence \n",
        "        # compare k individual and select best of them\n",
        "        tournament_list = {}\n",
        "        for i in range(len(fitness)):\n",
        "            if i in picked_index:\n",
        "                tournament_list[i] = fitness[i]\n",
        "        # get key(index) of largest fitness in the dictionary\n",
        "        best_individual_index = max(tournament_list, key=tournament_list.get)\n",
        "        if best_individual_index not in selected_to_mate: # without replacement\n",
        "            selected_to_mate.append(best_individual_index)\n",
        "            current_member += 1\n",
        "    # student code ends\n",
        "    \n",
        "    return selected_to_mate"
      ],
      "metadata": {
        "id": "Bc0SR13V_a4X"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Uniform"
      ],
      "metadata": {
        "id": "QJkQm4eBFtFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_uniform (population_size, mating_pool_size):\n",
        "    \"\"\"Random uniform selection\"\"\"\n",
        "\n",
        "    selected_to_mate = []\n",
        "\n",
        "    # student code starts\n",
        "\n",
        "    # same chance to be selected as a parent\n",
        "    selected_to_mate = random.choices(range(1,population_size), k=mating_pool_size)\n",
        "    # student code ends\n",
        "    \n",
        "    return selected_to_mate"
      ],
      "metadata": {
        "id": "uSfay0B2_hNM"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Survivor Selection"
      ],
      "metadata": {
        "id": "sks7za4N_rAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (miu + lambda)"
      ],
      "metadata": {
        "id": "FLSMO5PtFX-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mu_plus_lambda(current_pop, current_fitness, offspring, offspring_fitness):\n",
        "    \"\"\"mu+lambda selection\"\"\"\n",
        "    population = []\n",
        "    fitness = []\n",
        "\n",
        "    # student code starts\n",
        "\n",
        "    # only ranked population not pick the top individuals\n",
        "    # offspring and parent merged and ranked according to fitness\n",
        "    pop_size = len(current_pop)\n",
        "    merge_pop = list(current_pop).copy()\n",
        "    merge_fit = list(current_fitness).copy()\n",
        "\n",
        "    # concat population\n",
        "    for i in range(len(offspring)):\n",
        "        merge_pop.append(offspring[i])\n",
        "        merge_fit.append(offspring_fitness[i])\n",
        "\n",
        "\n",
        "    # store fitness, pop as tuple pairs\n",
        "    merge_tup = []\n",
        "    for i in range(len(merge_fit)):\n",
        "        merge_tup.append((merge_fit[i],merge_pop[i]))\n",
        "   \n",
        "    # sort tuple list according to fitness\n",
        "    merge_tup.sort(key=lambda a: a[0],reverse=True)\n",
        "\n",
        "\n",
        "    # get top 20 fitness population\n",
        "    top_tup = merge_tup[0:pop_size]\n",
        "    # get first element of tuple list: fitness\n",
        "    fitness = (list(zip(*top_tup))[0])\n",
        "    # get second element of tuple list: population\n",
        "    population = (list(zip(*top_tup))[1])\n",
        "    # student code ends\n",
        "    \n",
        "    return population, fitness\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dONA3IGz_s0R"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (miu, lambda)"
      ],
      "metadata": {
        "id": "Rskn0BPrFcPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def replacement(current_pop, current_fitness, offspring, offspring_fitness):\n",
        "    \"\"\"replacement selection\"\"\"\n",
        "\n",
        "    population = []\n",
        "    fitness = []\n",
        "\n",
        "    # student code starts\n",
        "    pop_tup = []\n",
        "    offspring_size = len(offspring_fitness)\n",
        "    list_pop = list(current_pop).copy()\n",
        "    list_fit = list(current_fitness).copy()\n",
        "    list_off = list(offspring).copy()\n",
        "    list_off_fit = list(offspring_fitness).copy()\n",
        "\n",
        "    # store as [(fitness,population), (fitness,population), ....]\n",
        "    for i in range(len(list_fit)):\n",
        "        pop_tup.append((list_fit[i],list_pop[i]))\n",
        "    # sort population only tuple list according to fitness\n",
        "    pop_tup.sort(key=lambda a: a[0],reverse=True)\n",
        "\n",
        "    # replace the worst n(offspring_size) lambda pop with offspring\n",
        "    pop_tup = pop_tup[:len(pop_tup)-offspring_size]\n",
        "\n",
        "    for i in range(offspring_size):\n",
        "        pop_tup.append((list_off_fit[i],list_off[i]))\n",
        "\n",
        "    # get first element of tuple list: fitness\n",
        "    fitness = (list(zip(*pop_tup))[0])\n",
        "    # get second element of tuple list: population\n",
        "    population = (list(zip(*pop_tup))[1])\n",
        "    \n",
        "    # student code ends\n",
        "    \n",
        "    return population, fitness\n",
        "\n"
      ],
      "metadata": {
        "id": "s-HiRAg_Fd56"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### random uniform"
      ],
      "metadata": {
        "id": "5cxQMzvsFhgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_uniform(current_pop, current_fitness, offspring, offspring_fitness):\n",
        "    \"\"\"random uniform selection\"\"\"\n",
        "    population = []\n",
        "    fitness = []\n",
        "\n",
        "    # student code starts\n",
        "    pop_size = len(current_pop)\n",
        "    merge_pop = list(current_pop).copy()\n",
        "    merge_fit = list(current_fitness).copy()\n",
        "\n",
        "    # concat population\n",
        "    for i in offspring:\n",
        "        merge_pop.append(i)\n",
        "    for i in offspring_fitness:\n",
        "        merge_fit.append(i)\n",
        "    # store fitness, pop as tuple pairs\n",
        "    merge_tup = []\n",
        "    for i in range(len(merge_fit)):\n",
        "        merge_tup.append((merge_fit[i],merge_pop[i]))\n",
        "\n",
        "    new_pop_tuplist = []\n",
        "    # random select\n",
        "    rdm_indexes = random.sample(range(len(merge_fit)),20)\n",
        "    for i in range(len(merge_tup)):\n",
        "        if i in rdm_indexes:\n",
        "            new_pop_tuplist.append(merge_tup[i])\n",
        "    \n",
        "    # get first element of tuple list: fitness\n",
        "    fitness = (list(zip(*new_pop_tuplist))[0])\n",
        "    # get second element of tuple list: population\n",
        "    population = (list(zip(*new_pop_tuplist))[1])\n",
        " \n",
        "    # student code ends\n",
        "    \n",
        "    return population, fitness\n"
      ],
      "metadata": {
        "id": "SgsYTwgwFg2l"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recombination - permutation_cut_and_crossfill"
      ],
      "metadata": {
        "id": "ju2yomSNSf_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def permutation_cut_and_crossfill (parent1, parent2):\n",
        "    \"\"\"cut-and-crossfill crossover for permutation representations\"\"\"\n",
        "\n",
        "    offspring1 = []\n",
        "    offspring2 = []\n",
        "    # print(\"parent1:\",parent1)\n",
        "    # print(\"parent2:\",parent2)\n",
        "    # student code begin\n",
        "    permu_length = len(parent1)\n",
        "    # select crossover point (not start or end)\n",
        "    crossover_point = random.randint(1,permu_length-2)\n",
        "    len1 = 0\n",
        "    len2 = 0\n",
        "    # form offsprings\n",
        "    offspring1 = parent1[:crossover_point] # keep parent 1 until point\n",
        "    offspring2 = parent2[:crossover_point] # keep parent 2 until point\n",
        "\n",
        "    # concat the parent after crossover point and parent before crossover point\n",
        "    temp2 = parent2[crossover_point:] + parent2[:crossover_point] \n",
        "    temp1 = parent1[crossover_point:] + parent1[:crossover_point] \n",
        "    while len1 < permu_length:\n",
        "        for i in temp2:\n",
        "            if i not in offspring1:\n",
        "                offspring1.append(i)\n",
        "            len1 = len(offspring1)\n",
        "\n",
        "\n",
        "    while len2 < permu_length:\n",
        "        for i in temp1:\n",
        "            if i not in offspring2:\n",
        "                offspring2.append(i)\n",
        "            len2 = len(offspring2)\n",
        "\n",
        "    # student code end\n",
        "    # print(\"offspring1:\",offspring1)\n",
        "    # print(\"offspring2:\",offspring2)\n",
        "    return offspring1, offspring2\n"
      ],
      "metadata": {
        "id": "zZYM73GZSfIe"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutation"
      ],
      "metadata": {
        "id": "wqqh6ecVSjSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### swap"
      ],
      "metadata": {
        "id": "vtM5YCpjS5sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def permutation_swap (individual):\n",
        "    \"\"\"Mutate a permutation\"\"\"\n",
        "\n",
        "    mutant = individual.copy()\n",
        "    \n",
        "    # student code starts\n",
        "    \n",
        "    # swap value of two randomly chosen positions\n",
        "    permu_length = len(mutant)\n",
        "    positions = range(permu_length)\n",
        "    pos1,pos2 = random.sample(positions,2)\n",
        "    mutant[pos1],mutant[pos2] = mutant[pos2],mutant[pos1] \n",
        "   \n",
        "    # student code ends\n",
        "    \n",
        "    return mutant"
      ],
      "metadata": {
        "id": "InusgFnmSmXF"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "r8WnIK9eRFsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = 77\n",
        "population_size = 100\n",
        "mutation_rate = 0.05\n",
        "mating_pool_size = 5\n",
        "tournament_size = 10\n",
        "\n",
        "population = initialize(input, population_size)\n",
        "# combine every 5 item together\n",
        "pop_combine=[list(itertools.chain.from_iterable(itertools.islice(population,i,i+5))) for i in range(0,len(population),5)]\n",
        "# convert population from list to a string for fitness calculation\n",
        "pop_to_str = [None] * len(pop_combine)\n",
        "for i in range(len(pop_combine)):\n",
        "  pop_to_str[i] = ''.join(pop_combine[i])\n",
        "\n",
        "for i in range(len(pop_to_str)):\n",
        "  print(\"pop_to_str\",i, \":\", fitness(pop_to_str[i]))\n",
        "\n",
        "\n",
        "#for i in population\n",
        "#fit = fitness(population)\n",
        "# while True:\n",
        "#   fit = fitness(population)\n",
        "#  selected_mat = tournament(fit, mating_pool_size, tournament_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Is2UkYMRFEL",
        "outputId": "fc1ae5ee-6e2b-4c5c-fb28-5ff770167718"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Not enough data to run test!\n",
            "pop_to_str 0 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 1 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 2 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 3 : 3\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 4 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 5 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 6 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 7 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 8 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 9 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 10 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 11 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 12 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 13 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 14 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 15 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 16 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 17 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 18 : 4\n",
            "\t Not enough data to run test!\n",
            "pop_to_str 19 : 4\n"
          ]
        }
      ]
    }
  ]
}