{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import asyncio"
      ],
      "metadata": {
        "id": "A32CGYWMYLPE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wywI0RR5s80Y"
      },
      "outputs": [],
      "source": [
        "async def monobit(bin_data):\n",
        "    \"\"\"\n",
        "    Note that this description is taken from the NIST documentation [1]\n",
        "    [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  \n",
        "    The focus of this test is the proportion of zeros and ones for the entire sequence. The purpose of this test is\n",
        "    to determine whether the number of ones and zeros in a sequence are approximately the same as would be expected\n",
        "    for a truly random sequence. This test assesses the closeness of the fraction of ones to 1/2, that is the number\n",
        "    of ones and zeros ina  sequence should be about the same. All subsequent tests depend on this test.\n",
        "  \n",
        "    :param bin_data: a binary string\n",
        "    :return: the p-value from the test\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    # If the char is 0 minus 1, else add 1\n",
        "    for char in bin_data:\n",
        "        if char == '0':\n",
        "            count -= 1\n",
        "        else:\n",
        "            count += 1\n",
        "    # Calculate the p value\n",
        "    sobs = count / math.sqrt(len(bin_data))\n",
        "    p_val = spc.erfc(math.fabs(sobs) / math.sqrt(2))\n",
        "    return p_val"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def block_frequency(bin_data, block_size=128):\n",
        "    \"\"\"\n",
        "    Note that this description is taken from the NIST documentation [1]\n",
        "    [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "    The focus of this tests is the proportion of ones within M-bit blocks. The purpose of this tests is to determine\n",
        "    whether the frequency of ones in an M-bit block is approximately M/2, as would be expected under an assumption\n",
        "    of randomness. For block size M=1, this test degenerates to the monobit frequency test.\n",
        "    :param bin_data: a binary string\n",
        "    :return: the p-value from the test\n",
        "    :param block_size: the size of the blocks that the binary sequence is partitioned into\n",
        "    \"\"\"\n",
        "    # Work out the number of blocks, discard the remainder\n",
        "    num_blocks = math.floor(len(bin_data) / block_size)\n",
        "    block_start, block_end = 0, block_size\n",
        "    # Keep track of the proportion of ones per block\n",
        "    proportion_sum = 0.0\n",
        "    for i in range(num_blocks):\n",
        "        # Slice the binary string into a block\n",
        "        block_data = bin_data[block_start:block_end]\n",
        "        # Keep track of the number of ones\n",
        "        ones_count = 0\n",
        "        for char in block_data:\n",
        "            if char == '1':\n",
        "                ones_count += 1\n",
        "        pi = ones_count / block_size\n",
        "        proportion_sum += pow(pi - 0.5, 2.0)\n",
        "        # Update the slice locations\n",
        "        block_start += block_size\n",
        "        block_end += block_size\n",
        "    # Calculate the p-value\n",
        "    chi_squared = 4.0 * block_size * proportion_sum\n",
        "    p_val = spc.gammaincc(num_blocks / 2, chi_squared / 2)\n",
        "    return p_val"
      ],
      "metadata": {
        "id": "iTmwo3k7tJ1y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def independent_runs(bin_data: str):\n",
        "        \"\"\"\n",
        "        Note that this description is taken from the NIST documentation [1]\n",
        "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "        The focus of this tests if the total number of runs in the sequences, where a run is an uninterrupted sequence\n",
        "        of identical bits. A run of length k consists of k identical bits and is bounded before and after with a bit of\n",
        "        the opposite value. The purpose of the runs tests is to determine whether the number of runs of ones and zeros\n",
        "        of various lengths is as expected for a random sequence. In particular, this tests determines whether the\n",
        "        oscillation between zeros and ones is either too fast or too slow.\n",
        "        :param bin_data: a binary string\n",
        "        :return: the p-value from the test\n",
        "        \"\"\"\n",
        "        ones_count, n = 0, len(bin_data)\n",
        "        for char in bin_data:\n",
        "            if char == '1':\n",
        "                ones_count += 1\n",
        "        p, vobs = float(ones_count / n), 1\n",
        "        tau = 2 / math.sqrt(len(bin_data))\n",
        "        if abs(p - 0.5) > tau:\n",
        "            return 0.0\n",
        "        else:\n",
        "            for i in range(1, n):\n",
        "                if bin_data[i] != bin_data[i - 1]:\n",
        "                    vobs += 1\n",
        "            # expected_runs = 1 + 2 * (n - 1) * 0.5 * 0.5\n",
        "            # print(\"\\t\", Colours.Italics + \"Observed runs =\", vobs, \"Expected runs\", expected_runs, Colours.End)\n",
        "            num = abs(vobs - 2.0 * n * p * (1.0 - p))\n",
        "            den = 2.0 * math.sqrt(2.0 * n) * p * (1.0 - p)\n",
        "            p_val = spc.erfc(float(num / den))\n",
        "            return p_val"
      ],
      "metadata": {
        "id": "myNQHY_itMnf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def longest_runs(bin_data: str):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of the tests is the longest run of ones within M-bit blocks. The purpose of this tests is to determine\n",
        "  whether the length of the longest run of ones within the tested sequences is consistent with the length of the\n",
        "  longest run of ones that would be expected in a random sequence. Note that an irregularity in the expected\n",
        "  length of the longest run of ones implies that there is also an irregularity ub tge expected length of the long\n",
        "  est run of zeroes. Therefore, only one test is necessary for this statistical tests of randomness\n",
        "  :param bin_data: a binary string\n",
        "  :return: the p-value from the test\n",
        "  \"\"\"\n",
        "  if len(bin_data) < 128:\n",
        "      print(\"\\t\", \"Not enough data to run test!\")\n",
        "      return -1.0\n",
        "  elif len(bin_data) < 6272:\n",
        "      k, m = 3, 8\n",
        "      v_values = [1, 2, 3, 4]\n",
        "      pik_values = [0.21484375, 0.3671875, 0.23046875, 0.1875]\n",
        "  elif len(bin_data) < 75000:\n",
        "      k, m = 5, 128\n",
        "      v_values = [4, 5, 6, 7, 8, 9]\n",
        "      pik_values = [0.1174035788, 0.242955959, 0.249363483, 0.17517706, 0.102701071, 0.112398847]\n",
        "  else:\n",
        "      k, m = 6, 10000\n",
        "      v_values = [10, 11, 12, 13, 14, 15, 16]\n",
        "      pik_values = [0.0882, 0.2092, 0.2483, 0.1933, 0.1208, 0.0675, 0.0727]\n",
        "\n",
        "  # Work out the number of blocks, discard the remainder\n",
        "  # pik = [0.2148, 0.3672, 0.2305, 0.1875]\n",
        "  num_blocks = math.floor(len(bin_data) / m)\n",
        "  frequencies = numpy.zeros(k + 1)\n",
        "  block_start, block_end = 0, m\n",
        "  for i in range(num_blocks):\n",
        "      # Slice the binary string into a block\n",
        "      block_data = bin_data[block_start:block_end]\n",
        "      # Keep track of the number of ones\n",
        "      max_run_count, run_count = 0, 0\n",
        "      for j in range(0, m):\n",
        "          if block_data[j] == '1':\n",
        "              run_count += 1\n",
        "              max_run_count = max(max_run_count, run_count)\n",
        "          else:\n",
        "              max_run_count = max(max_run_count, run_count)\n",
        "              run_count = 0\n",
        "      max_run_count = max(max_run_count, run_count)\n",
        "      if max_run_count < v_values[0]:\n",
        "          frequencies[0] += 1\n",
        "      for j in range(k):\n",
        "          if max_run_count == v_values[j]:\n",
        "              frequencies[j] += 1\n",
        "      if max_run_count > v_values[k - 1]:\n",
        "          frequencies[k] += 1\n",
        "      block_start += m\n",
        "      block_end += m\n",
        "  # print(frequencies)\n",
        "  chi_squared = 0\n",
        "  for i in range(len(frequencies)):\n",
        "      chi_squared += (pow(frequencies[i] - (num_blocks * pik_values[i]), 2.0)) / (num_blocks * pik_values[i])\n",
        "  p_val = spc.gammaincc(float(k / 2), float(chi_squared / 2))\n",
        "  return p_val"
      ],
      "metadata": {
        "id": "3SzmLt47tQkI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def matrix_rank(bin_data: str, matrix_size=32):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of the test is the rank of disjoint sub-matrices of the entire sequence. The purpose of this test is\n",
        "  to check for linear dependence among fixed length sub strings of the original sequence. Note that this test\n",
        "  also appears in the DIEHARD battery of tests.\n",
        "  :param bin_data: a binary string\n",
        "  :return: the p-value from the test\n",
        "  \"\"\"\n",
        "  shape = (matrix_size, matrix_size)\n",
        "  n = len(bin_data)\n",
        "  block_size = int(matrix_size * matrix_size)\n",
        "  num_m = math.floor(n / (matrix_size * matrix_size))\n",
        "  block_start, block_end = 0, block_size\n",
        "  # print(q, n, num_m, block_size)\n",
        "\n",
        "  if num_m > 0:\n",
        "      max_ranks = [0, 0, 0]\n",
        "      for im in range(num_m):\n",
        "          block_data = bin_data[block_start:block_end]\n",
        "          block = numpy.zeros(len(block_data))\n",
        "          for i in range(len(block_data)):\n",
        "              if block_data[i] == '1':\n",
        "                  block[i] = 1.0\n",
        "          m = block.reshape(shape)\n",
        "          ranker = BinaryMatrix(m, matrix_size, matrix_size)\n",
        "          rank = ranker.compute_rank()\n",
        "          # print(rank)\n",
        "          if rank == matrix_size:\n",
        "              max_ranks[0] += 1\n",
        "          elif rank == (matrix_size - 1):\n",
        "              max_ranks[1] += 1\n",
        "          else:\n",
        "              max_ranks[2] += 1\n",
        "          # Update index trackers\n",
        "          block_start += block_size\n",
        "          block_end += block_size\n",
        "\n",
        "      piks = [1.0, 0.0, 0.0]\n",
        "      for x in range(1, 50):\n",
        "          piks[0] *= 1 - (1.0 / (2 ** x))\n",
        "      piks[1] = 2 * piks[0]\n",
        "      piks[2] = 1 - piks[0] - piks[1]\n",
        "\n",
        "      chi = 0.0\n",
        "      for i in range(len(piks)):\n",
        "          chi += pow((max_ranks[i] - piks[i] * num_m), 2.0) / (piks[i] * num_m)\n",
        "      p_val = math.exp(-chi / 2)\n",
        "      return p_val\n",
        "  else:\n",
        "      return -1.0"
      ],
      "metadata": {
        "id": "10sDbLwntTF6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def spectral(bin_data: str):\n",
        "        \"\"\"\n",
        "        Note that this description is taken from the NIST documentation [1]\n",
        "        [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "        The focus of this test is the peak heights in the Discrete Fourier Transform of the sequence. The purpose of\n",
        "        this test is to detect periodic features (i.e., repetitive patterns that are near each other) in the tested\n",
        "        sequence that would indicate a deviation from the assumption of randomness. The intention is to detect whether\n",
        "        the number of peaks exceeding the 95 % threshold is significantly different than 5 %.\n",
        "        :param bin_data: a binary string\n",
        "        :return: the p-value from the test\n",
        "        \"\"\"\n",
        "        n = len(bin_data)\n",
        "        plus_minus_one = []\n",
        "        for char in bin_data:\n",
        "            if char == '0':\n",
        "                plus_minus_one.append(-1)\n",
        "            elif char == '1':\n",
        "                plus_minus_one.append(1)\n",
        "        # Product discrete fourier transform of plus minus one\n",
        "        s = sff.fft(plus_minus_one)\n",
        "        modulus = numpy.abs(s[0:n / 2])\n",
        "        tau = numpy.sqrt(numpy.log(1 / 0.05) * n)\n",
        "        # Theoretical number of peaks\n",
        "        count_n0 = 0.95 * (n / 2)\n",
        "        # Count the number of actual peaks m > T\n",
        "        count_n1 = len(numpy.where(modulus < tau)[0])\n",
        "        # Calculate d and return the p value statistic\n",
        "        d = (count_n1 - count_n0) / numpy.sqrt(n * 0.95 * 0.05 / 4)\n",
        "        p_val = spc.erfc(abs(d) / numpy.sqrt(2))\n",
        "        return p_val"
      ],
      "metadata": {
        "id": "fhNJ0ivNtXQM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def universal(bin_data: str):\n",
        "    \"\"\"\n",
        "    Note that this description is taken from the NIST documentation [1]\n",
        "    [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "    The focus of this test is the number of bits between matching patterns (a measure that is related to the\n",
        "    length of a compressed sequence). The purpose of the test is to detect whether or not the sequence can be\n",
        "    significantly compressed without loss of information. A significantly compressible sequence is considered\n",
        "    to be non-random. **This test is always skipped because the requirements on the lengths of the binary\n",
        "    strings are too high i.e. there have not been enough trading days to meet the requirements.\n",
        "    :param bin_data: a binary string\n",
        "    :return: the p-value from the test\n",
        "    \"\"\"\n",
        "    # The below table is less relevant for us traders and markets than it is for security people\n",
        "    n = len(bin_data)\n",
        "    pattern_size = 5\n",
        "    if n >= 387840:\n",
        "        pattern_size = 6\n",
        "    if n >= 904960:\n",
        "        pattern_size = 7\n",
        "    if n >= 2068480:\n",
        "        pattern_size = 8\n",
        "    if n >= 4654080:\n",
        "        pattern_size = 9\n",
        "    if n >= 10342400:\n",
        "        pattern_size = 10\n",
        "    if n >= 22753280:\n",
        "        pattern_size = 11\n",
        "    if n >= 49643520:\n",
        "        pattern_size = 12\n",
        "    if n >= 107560960:\n",
        "        pattern_size = 13\n",
        "    if n >= 231669760:\n",
        "        pattern_size = 14\n",
        "    if n >= 496435200:\n",
        "        pattern_size = 15\n",
        "    if n >= 1059061760:\n",
        "        pattern_size = 16\n",
        "\n",
        "    if 5 < pattern_size < 16:\n",
        "        # Create the biggest binary string of length pattern_size\n",
        "        ones = \"\"\n",
        "        for i in range(pattern_size):\n",
        "            ones += \"1\"\n",
        "\n",
        "        # How long the state list should be\n",
        "        num_ints = int(ones, 2)\n",
        "        vobs = numpy.zeros(num_ints + 1)\n",
        "\n",
        "        # Keeps track of the blocks, and whether were are initializing or summing\n",
        "        num_blocks = math.floor(n / pattern_size)\n",
        "        init_bits = 10 * pow(2, pattern_size)\n",
        "        test_bits = num_blocks - init_bits\n",
        "\n",
        "        # These are the expected values assuming randomness (uniform)\n",
        "        c = 0.7 - 0.8 / pattern_size + (4 + 32 / pattern_size) * pow(test_bits, -3 / pattern_size) / 15\n",
        "        variance = [0, 0, 0, 0, 0, 0, 2.954, 3.125, 3.238, 3.311, 3.356, 3.384, 3.401, 3.410, 3.416, 3.419, 3.421]\n",
        "        expected = [0, 0, 0, 0, 0, 0, 5.2177052, 6.1962507, 7.1836656, 8.1764248, 9.1723243,\n",
        "                    10.170032, 11.168765, 12.168070, 13.167693, 14.167488, 15.167379]\n",
        "        sigma = c * math.sqrt(variance[pattern_size] / test_bits)\n",
        "\n",
        "        cumsum = 0.0\n",
        "        for i in range(num_blocks):\n",
        "            block_start = i * pattern_size\n",
        "            block_end = block_start + pattern_size\n",
        "            block_data = bin_data[block_start: block_end]\n",
        "            # Work out what state we are in\n",
        "            int_rep = int(block_data, 2)\n",
        "\n",
        "            # Initialize the state list\n",
        "            if i < init_bits:\n",
        "                vobs[int_rep] = i + 1\n",
        "            else:\n",
        "                initial = vobs[int_rep]\n",
        "                vobs[int_rep] = i + 1\n",
        "                cumsum += math.log(i - initial + 1, 2)\n",
        "\n",
        "        # Calculate the statistic\n",
        "        phi = float(cumsum / test_bits)\n",
        "        stat = abs(phi - expected[pattern_size]) / (float(math.sqrt(2)) * sigma)\n",
        "        p_val = spc.erfc(stat)\n",
        "        return p_val\n",
        "    else:\n",
        "        return -1.0"
      ],
      "metadata": {
        "id": "7Ov5gDpxtX8_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def berlekamp_massey_algorithm(block_data: str):\n",
        "    \"\"\"\n",
        "    An implementation of the Berlekamp Massey Algorithm. Taken from Wikipedia [1]\n",
        "    [1] - https://en.wikipedia.org/wiki/Berlekamp-Massey_algorithm\n",
        "    The Berlekamp–Massey algorithm is an algorithm that will find the shortest linear feedback shift register (LFSR)\n",
        "    for a given binary output sequence. The algorithm will also find the minimal polynomial of a linearly recurrent\n",
        "    sequence in an arbitrary field. The field requirement means that the Berlekamp–Massey algorithm requires all\n",
        "    non-zero elements to have a multiplicative inverse.\n",
        "    :param block_data:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    n = len(block_data)\n",
        "    c = numpy.zeros(n)\n",
        "    b = numpy.zeros(n)\n",
        "    c[0], b[0] = 1, 1\n",
        "    l, m, i = 0, -1, 0\n",
        "    int_data = [int(el) for el in block_data]\n",
        "    while i < n:\n",
        "        v = int_data[(i - l):i]\n",
        "        v = v[::-1]\n",
        "        cc = c[1:l + 1]\n",
        "        d = (int_data[i] + numpy.dot(v, cc)) % 2\n",
        "        if d == 1:\n",
        "            temp = copy.copy(c)\n",
        "            p = numpy.zeros(n)\n",
        "            for j in range(0, l):\n",
        "                if b[j] == 1:\n",
        "                    p[j + i - m] = 1\n",
        "            c = (c + p) % 2\n",
        "            if l <= 0.5 * i:\n",
        "                l = i + 1 - l\n",
        "                m = i\n",
        "                b = temp\n",
        "        i += 1\n",
        "    return l"
      ],
      "metadata": {
        "id": "MXo-RnAnta2A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def linear_complexity(bin_data: str, block_size=500):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of this test is the length of a linear feedback shift register (LFSR). The purpose of this test is to\n",
        "  determine whether or not the sequence is complex enough to be considered random. Random sequences are\n",
        "  characterized by longer LFSRs. An LFSR that is too short implies non-randomness.\n",
        "  :param bin_data: a binary string\n",
        "  :param block_size: the size of the blocks to divide bin_data into. Recommended block_size >= 500\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  dof = 6\n",
        "  piks = [0.01047, 0.03125, 0.125, 0.5, 0.25, 0.0625, 0.020833]\n",
        "\n",
        "  t2 = (block_size / 3.0 + 2.0 / 9) / 2 ** block_size\n",
        "  mean = 0.5 * block_size + (1.0 / 36) * (9 + (-1) ** (block_size + 1)) - t2\n",
        "\n",
        "  num_blocks = int(len(bin_data) / block_size)\n",
        "  if num_blocks > 1:\n",
        "      block_end = block_size\n",
        "      block_start = 0\n",
        "      blocks = []\n",
        "      for i in range(num_blocks):\n",
        "          blocks.append(bin_data[block_start:block_end])\n",
        "          block_start += block_size\n",
        "          block_end += block_size\n",
        "\n",
        "      complexities = []\n",
        "      for block in blocks:\n",
        "          complexities.append(berlekamp_massey_algorithm(block))\n",
        "\n",
        "      t = ([-1.0 * (((-1) ** block_size) * (chunk - mean) + 2.0 / 9) for chunk in complexities])\n",
        "      vg = numpy.histogram(t, bins=[-9999999999, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 9999999999])[0][::-1]\n",
        "      im = ([((vg[ii] - num_blocks * piks[ii]) ** 2) / (num_blocks * piks[ii]) for ii in range(7)])\n",
        "\n",
        "      chi_squared = 0.0\n",
        "      for i in range(len(piks)):\n",
        "          chi_squared += im[i]\n",
        "      p_val = spc.gammaincc(dof / 2.0, chi_squared / 2.0)\n",
        "      return p_val\n",
        "  else:\n",
        "      return -1.0"
      ],
      "metadata": {
        "id": "YobvheC8teib"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def serial(bin_data: str, pattern_length=16, method=\"first\"):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of this test is the frequency of all possible overlapping m-bit patterns across the entire\n",
        "  sequence. The purpose of this test is to determine whether the number of occurrences of the 2m m-bit\n",
        "  overlapping patterns is approximately the same as would be expected for a random sequence. Random\n",
        "  sequences have uniformity; that is, every m-bit pattern has the same chance of appearing as every other\n",
        "  m-bit pattern. Note that for m = 1, the Serial test is equivalent to the Frequency test of Section 2.1.\n",
        "  :param bin_data: a binary string\n",
        "  :param pattern_length: the length of the pattern (m)\n",
        "  :return: the P value\n",
        "  \"\"\"\n",
        "  n = len(bin_data)\n",
        "  # Add first m-1 bits to the end\n",
        "  bin_data += bin_data[:pattern_length - 1:]\n",
        "\n",
        "  # Get max length one patterns for m, m-1, m-2\n",
        "  max_pattern = ''\n",
        "  for i in range(pattern_length + 1):\n",
        "      max_pattern += '1'\n",
        "\n",
        "  # Keep track of each pattern's frequency (how often it appears)\n",
        "  vobs_one = numpy.zeros(int(max_pattern[0:pattern_length:], 2) + 1)\n",
        "  vobs_two = numpy.zeros(int(max_pattern[0:pattern_length - 1:], 2) + 1)\n",
        "  vobs_thr = numpy.zeros(int(max_pattern[0:pattern_length - 2:], 2) + 1)\n",
        "\n",
        "  for i in range(n):\n",
        "      # Work out what pattern is observed\n",
        "      vobs_one[int(bin_data[i:i + pattern_length:], 2)] += 1\n",
        "      vobs_two[int(bin_data[i:i + pattern_length - 1:], 2)] += 1\n",
        "      vobs_thr[int(bin_data[i:i + pattern_length - 2:], 2)] += 1\n",
        "\n",
        "  vobs = [vobs_one, vobs_two, vobs_thr]\n",
        "  sums = numpy.zeros(3)\n",
        "  for i in range(3):\n",
        "      for j in range(len(vobs[i])):\n",
        "          sums[i] += pow(vobs[i][j], 2)\n",
        "      sums[i] = (sums[i] * pow(2, pattern_length - i) / n) - n\n",
        "\n",
        "  # Calculate the test statistics and p values\n",
        "  del1 = sums[0] - sums[1]\n",
        "  del2 = sums[0] - 2.0 * sums[1] + sums[2]\n",
        "  p_val_one = spc.gammaincc(pow(2, pattern_length - 1) / 2, del1 / 2.0)\n",
        "  p_val_two = spc.gammaincc(pow(2, pattern_length - 2) / 2, del2 / 2.0)\n",
        "\n",
        "  # For checking the outputs\n",
        "  if method == \"first\":\n",
        "      return p_val_one\n",
        "  elif method == \"both\":\n",
        "      return p_val_one, p_val_two\n",
        "  else:\n",
        "      # I am not sure if this is correct, but it makes sense to me.\n",
        "      return min(p_val_one, p_val_two)"
      ],
      "metadata": {
        "id": "bbcKMkc2tfGE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def approximate_entropy(bin_data: str, pattern_length=10):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  As with the Serial test of Section 2.11, the focus of this test is the frequency of all possible overlapping\n",
        "  m-bit patterns across the entire sequence. The purpose of the test is to compare the frequency of overlapping\n",
        "  blocks of two consecutive/adjacent lengths (m and m+1) against the expected result for a random sequence.\n",
        "  :param bin_data: a binary string\n",
        "  :param pattern_length: the length of the pattern (m)\n",
        "  :return: the P value\n",
        "  \"\"\"\n",
        "  n = len(bin_data)\n",
        "  # Add first m+1 bits to the end\n",
        "  # NOTE: documentation says m-1 bits but that doesnt make sense, or work.\n",
        "  bin_data += bin_data[:pattern_length + 1:]\n",
        "\n",
        "  # Get max length one patterns for m, m-1, m-2\n",
        "  max_pattern = ''\n",
        "  for i in range(pattern_length + 2):\n",
        "      max_pattern += '1'\n",
        "\n",
        "  # Keep track of each pattern's frequency (how often it appears)\n",
        "  vobs_one = numpy.zeros(int(max_pattern[0:pattern_length:], 2) + 1)\n",
        "  vobs_two = numpy.zeros(int(max_pattern[0:pattern_length + 1:], 2) + 1)\n",
        "\n",
        "  for i in range(n):\n",
        "      # Work out what pattern is observed\n",
        "      vobs_one[int(bin_data[i:i + pattern_length:], 2)] += 1\n",
        "      vobs_two[int(bin_data[i:i + pattern_length + 1:], 2)] += 1\n",
        "\n",
        "  # Calculate the test statistics and p values\n",
        "  vobs = [vobs_one, vobs_two]\n",
        "  sums = numpy.zeros(2)\n",
        "  for i in range(2):\n",
        "      for j in range(len(vobs[i])):\n",
        "          if vobs[i][j] > 0:\n",
        "              sums[i] += vobs[i][j] * math.log(vobs[i][j] / n)\n",
        "  sums /= n\n",
        "  ape = sums[0] - sums[1]\n",
        "  chi_squared = 2.0 * n * (math.log(2) - ape)\n",
        "  p_val = spc.gammaincc(pow(2, pattern_length - 1), chi_squared / 2.0)\n",
        "  return p_val"
      ],
      "metadata": {
        "id": "KzfDUvTtthTi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def cumulative_sums(bin_data: str, method=\"forward\"):\n",
        "  \"\"\"\n",
        "  Note that this description is taken from the NIST documentation [1]\n",
        "  [1] http://csrc.nist.gov/publications/nistpubs/800-22-rev1a/SP800-22rev1a.pdf\n",
        "  The focus of this test is the maximal excursion (from zero) of the random walk defined by the cumulative sum of\n",
        "  adjusted (-1, +1) digits in the sequence. The purpose of the test is to determine whether the cumulative sum of\n",
        "  the partial sequences occurring in the tested sequence is too large or too small relative to the expected\n",
        "  behavior of that cumulative sum for random sequences. This cumulative sum may be considered as a random walk.\n",
        "  For a random sequence, the excursions of the random walk should be near zero. For certain types of non-random\n",
        "  sequences, the excursions of this random walk from zero will be large.\n",
        "  :param bin_data: a binary string\n",
        "  :param method: the method used to calculate the statistic\n",
        "  :return: the P-value\n",
        "  \"\"\"\n",
        "  n = len(bin_data)\n",
        "  counts = numpy.zeros(n)\n",
        "  # Calculate the statistic using a walk forward\n",
        "  if method != \"forward\":\n",
        "      bin_data = bin_data[::-1]\n",
        "\n",
        "  ix = 0\n",
        "  for char in bin_data:\n",
        "      sub = 1\n",
        "      if char == '0':\n",
        "          sub = -1\n",
        "      if ix > 0:\n",
        "          counts[ix] = counts[ix - 1] + sub\n",
        "      else:\n",
        "          counts[ix] = sub\n",
        "      ix += 1\n",
        "\n",
        "  # This is the maximum absolute level obtained by the sequence\n",
        "  abs_max = numpy.max(numpy.abs(counts))\n",
        "\n",
        "  start = int(numpy.floor(0.25 * numpy.floor(-n / abs_max) + 1))\n",
        "  end = int(numpy.floor(0.25 * numpy.floor(n / abs_max) - 1))\n",
        "  terms_one = []\n",
        "  for k in range(start, end + 1):\n",
        "      sub = sst.norm.cdf((4 * k - 1) * abs_max / numpy.sqrt(n))\n",
        "      terms_one.append(sst.norm.cdf((4 * k + 1) * abs_max / numpy.sqrt(n)) - sub)\n",
        "\n",
        "  start = int(numpy.floor(0.25 * numpy.floor(-n / abs_max - 3)))\n",
        "  end = int(numpy.floor(0.25 * numpy.floor(n / abs_max) - 1))\n",
        "  terms_two = []\n",
        "  for k in range(start, end + 1):\n",
        "      sub = sst.norm.cdf((4 * k + 1) * abs_max / numpy.sqrt(n))\n",
        "      terms_two.append(sst.norm.cdf((4 * k + 3) * abs_max / numpy.sqrt(n)) - sub)\n",
        "\n",
        "  p_val = 1.0 - numpy.sum(numpy.array(terms_one))\n",
        "  p_val += numpy.sum(numpy.array(terms_two))\n",
        "  return p_val\n"
      ],
      "metadata": {
        "id": "81LfKJ69tjeH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness(sequence):\n",
        "  # 1. monobit test\n",
        "  monobit_test = int(monobit(sequence) > 0.01)\n",
        "\n",
        "  # 2. block frequency test\n",
        "  block_freq_test = int(block_frequency(sequence) > 0.01)\n",
        "\n",
        "  # 3. independent_runs test\n",
        "  runs_test = int(independent_runs(sequence) > 0.01)\n",
        "\n",
        "  \n",
        "  # 4. longest run\n",
        "  longest_runs_test = int(longest_runs(sequence) > 0.01)\n",
        "\n",
        "  # 5. matrix_rank\n",
        "  matrix_rank_test = int(matrix_rank(sequence) > 0.01)\n",
        "\n",
        "  # 6. spectral\n",
        "  # spectral_test = int(spectral(sequence) > 0.01)\n",
        "\n",
        "  # 7. universal\n",
        "  universal_test = int(universal(sequence) > 0.01)\n",
        "\n",
        "  # 8. linear_complexity\n",
        "  linear_complexity_test = int(linear_complexity(sequence) > 0.01)\n",
        "\n",
        "  # 9. serial\n",
        "  serial_test = int(serial(sequence) > 0.01)\n",
        "\n",
        "  # 10. approximate_entropy\n",
        "  approximate_entropy_test = int(approximate_entropy(sequence) > 0.01)\n",
        "\n",
        "  # 11. cumulative_sums\n",
        "  cumulative_sums_test = int(cumulative_sums(sequence) > 0.01)\n",
        "\n",
        "  result = monobit_test + block_freq_test + matrix_rank_test\n",
        "  ## spectral has numpy issue, runs_test + longest_runs_test need multiple runs\n",
        "  # result += spectral_test + runs_test + longest_runs_test\n",
        "  result += universal_test + linear_complexity_test + serial_test\n",
        "  result += approximate_entropy_test + cumulative_sums_test\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "Lj3EuGi5tmCE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#使用asyncio.run即可\n",
        "async def concurrent(seq):\n",
        "  await asyncio.gather(monobit(seq), block_frequency(seq), independent_runs(seq), longest_runs(seq), matrix_rank(seq), spectral(seq), universal(seq), linear_complexity(seq), serial(seq), approximate_entropy(seq), cumulative_sums(seq))"
      ],
      "metadata": {
        "id": "o-9BMTHhYc1Z"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}